{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarized data: \n",
      "\n",
      " [[1. 0. 1. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[3, -1.5,  2, -5.4], [ 0,  4,  -0.3, 2.1], [ 1,  3.3, -1.9, -4.3]])\n",
    "# Put 1 if value is greater than 1.4, else 0. 1.4 will be converted to 0.\n",
    "bindata = preprocessing.Binarizer(threshold=1.4).transform(data)\n",
    "print (\"Binarized data: \\n\\n\", bindata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Mean Removal / Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean across each columns (Before):  [ 1.33333333  1.93333333 -0.06666667 -2.53333333]\n",
      "\n",
      "Standard Deviation: (Before):  [1.24721913 2.44449495 1.60069429 3.30689515]\n",
      "\n",
      "\n",
      "scaled_data:  [[ 1.33630621 -1.40451644  1.29110641 -0.86687558]\n",
      " [-1.06904497  0.84543708 -0.14577008  1.40111286]\n",
      " [-0.26726124  0.55907936 -1.14533633 -0.53423728]]\n",
      "\n",
      "Mean across each columns (After):  [ 5.55111512e-17 -1.11022302e-16 -7.40148683e-17 -7.40148683e-17]\n",
      "\n",
      "Standard Deviation (After):   [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[3, -1.5,  2, -5.4], [ 0,  4,  -0.3, 2.1], [ 1,  3.3, -1.9, -4.3]])\n",
    "print (\"\\nMean across each columns (Before): \", data.mean(axis=0))\n",
    "print (\"\\nStandard Deviation: (Before): \", data.std(axis=0))\n",
    "\n",
    "# Transform the data to center it by removing the mean value of each feature, \n",
    "# then scale it by dividing each features by their standard deviation. This transformation is done for transforming all the data \n",
    "# proportionally.\n",
    "# Transformation also known as Gaussian with zero mean and unit variance.\n",
    "scaled_data = preprocessing.scale(data)\n",
    "print (\"\\n\\nscaled_data: \", scaled_data)\n",
    "                \n",
    "print (\"\\nMean across each columns (After): \", scaled_data.mean(axis=0))\n",
    "print (\"\\nStandard Deviation (After):  \", scaled_data.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Scaling\n",
    "      StandardScalar\n",
    "      MinMaxScalar - Feature to be in 0 to 1 range.\n",
    "      Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "scaled_data:  [[1.         0.         1.         0.        ]\n",
      " [0.         1.         0.41025641 1.        ]\n",
      " [0.33333333 0.87272727 0.         0.14666667]]\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScalar\n",
    "# X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "# X_scaled = X_std * (max - min) + min\n",
    "data = np.array([[3, -1.5,  2, -5.4], [ 0,  4,  -0.3, 2.1], [ 1,  3.3, -1.9, -4.3]])\n",
    "minmax_scalar = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "data_minmax = minmax_scalar.fit_transform(data)\n",
    "print (\"\\nscaled_data: \", data_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Normalization\n",
    "   -- bringing the value of each feature vector on a common scale\n",
    "   - l1 - Least absolute devaitions: Sum of absolute values on each row is 1. It is insensitive to outliers.\n",
    "   - l2 - Least squares: Sum of squares on each row is 1. Takes outliers in considerations during training.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L1 Normalized data:  [[ 0.25210084 -0.12605042  0.16806723 -0.45378151]\n",
      " [ 0.          0.625      -0.046875    0.328125  ]\n",
      " [ 0.0952381   0.31428571 -0.18095238 -0.40952381]]\n",
      "\n",
      "L2 Normalized data:  [[ 0.45017448 -0.22508724  0.30011632 -0.81031406]\n",
      " [ 0.          0.88345221 -0.06625892  0.46381241]\n",
      " [ 0.17152381  0.56602858 -0.32589524 -0.73755239]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[3, -1.5,  2, -5.4], [ 0,  4,  -0.3, 2.1], [ 1,  3.3, -1.9, -4.3]])\n",
    "data_l1 = preprocessing.normalize(data, norm = 'l1')\n",
    "data_l2 = preprocessing.normalize(data, norm = 'l2')\n",
    "\n",
    "print (\"\\nL1 Normalized data: \", data_l1)\n",
    "print (\"\\nL2 Normalized data: \", data_l2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. One-Hot Encoding / Dummy Variables creation\n",
    "- Used on categorical variables\n",
    "- It replaces a categorical variable/feature with one or more feature that will take the values of either 0 or 1.\n",
    "- Increses data burden\n",
    "- Increses the efficiency of the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded vector:\n",
      " [[0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding\n",
    "encoder = preprocessing.OneHotEncoder()\n",
    "encoder.fit([[0, 2, 1, 12], [1, 3, 5, 3], [2, 3, 2, 12], [1, 2, 4, 3]])\n",
    "encoded_vector = encoder.transform([[2, 3, 5, 3]]).toarray()\n",
    "print (\"\\nEncoded vector:\\n\", encoded_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sx    rk  yr         dg  yd     sl\n",
      "0    male  full  25  doctorate  35  36350\n",
      "1    male  full  13  doctorate  22  35350\n",
      "2    male  full  10  doctorate  23  28200\n",
      "3  female  full   7  doctorate  27  26775\n",
      "4    male  full  19    masters  30  33696\n",
      "   female  male\n",
      "0       0     1\n",
      "1       0     1\n",
      "2       0     1\n",
      "3       1     0\n",
      "4       0     1\n",
      "       sx    rk  yr         dg  yd     sl  female  male\n",
      "0    male  full  25  doctorate  35  36350       0     1\n",
      "1    male  full  13  doctorate  22  35350       0     1\n",
      "2    male  full  10  doctorate  23  28200       0     1\n",
      "3  female  full   7  doctorate  27  26775       1     0\n",
      "4    male  full  19    masters  30  33696       0     1\n",
      "       sx    rk  yr         dg  yd     sl  female_x  male_x  female_y  male_y\n",
      "0    male  full  25  doctorate  35  36350         0       1         0       1\n",
      "1    male  full  13  doctorate  22  35350         0       1         0       1\n",
      "2    male  full  10  doctorate  23  28200         0       1         0       1\n",
      "3  female  full   7  doctorate  27  26775         1       0         1       0\n",
      "4    male  full  19    masters  30  33696         0       1         0       1\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_table(\"http://data.princeton.edu/wws509/datasets/salary.dat\", delim_whitespace=True)\n",
    "# Take a look\n",
    "print (df.head())\n",
    "\n",
    "# Encode sx column into one-hot encoding\n",
    "dummy = pd.get_dummies(df['sx'])\n",
    "print (dummy.head())\n",
    "\n",
    "# Concatenate original and newly created dummy data frame\n",
    "df = pd.concat([df, dummy], axis = 1)\n",
    "print (df.head())\n",
    "\n",
    "# Merge original and newly created dummy data frame\n",
    "df = df.merge(dummy, left_index = True, right_index = True)\n",
    "print (df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
